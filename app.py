import streamlit as st
import pandas as pd
import numpy as np
import os
import cv2
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
import plotly.express as px
import plotly.graph_objects as go
from collections import Counter
from wordcloud import WordCloud
import imagesize
import matplotlib.pyplot as plt
import seaborn as sns

# -----------------------------------
# CONFIG
# -----------------------------------
IMG_DIR = "./Flipkart/Images/"
EMB_PATH = "./clip_embeddings.npy"
LABELS_PATH = "./clip_labels.npy"
DESCRIPTION_PATH = "./produits_clip.csv"

# -----------------------------------
# CHARGEMENT DES DONNÃ‰ES
# -----------------------------------
@st.cache_resource
def load_data():
    embeddings = np.load(EMB_PATH)
    labels = np.load(LABELS_PATH)
    description = pd.read_csv(DESCRIPTION_PATH)
    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
    return embeddings, labels, description

embeddings, labels, description = load_data()

# -----------------------------------
# FONCTIONS UTILES
# -----------------------------------
def cv2_read_rgb(path):
    img = cv2.imread(path)
    if img is None: return None
    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

def preprocess_uploaded_file(file):
    file_bytes = np.frombuffer(file.read(), np.uint8)
    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

def encode_image_clip(image_rgb, model, processor, device):
    import torch  # <-- IMPORTANT, sinon torch est importÃ© globalement
    dummy_text = [""]
    inputs = processor(text=dummy_text, images=[image_rgb], return_tensors="pt", padding=True).to(device)
    with torch.no_grad():
        outputs = model(**inputs)
    img_emb = outputs.image_embeds.cpu().numpy()
    img_emb /= np.linalg.norm(img_emb, axis=-1, keepdims=True)
    return img_emb[0]

# -----------------------------------
# UI
# -----------------------------------
st.set_page_config(page_title="POC modÃ¨le CLIP", layout="wide")
tabs = st.tabs(["Analyse exploratoire", "PrÃ©diction CLIP"])
tab_eda, tab_search = tabs

# ---------------------------
# Page 1 : Analyse exploratoire des donnÃ©es
# ---------------------------
with tab_eda:
    # Sidebar: about + shared category filter
    categories_list = sorted(description['category'].fillna('N/A').unique())
    filter_options = ["Toutes les catÃ©gories"] + categories_list

    st.sidebar.header("Ã€ propos")
    st.sidebar.info("""
    Cette application permet restituer les rÃ©sultats d'un POC 
    sur la multi-modalitÃ© pour classifier automatiquement des produits de consommation.
    - En premiÃ¨re page nous retrouvons une analyse exploratoire des donnÃ©es textuelles et visuelles.
    - En seconde page, une interface de classification des produits via le modÃ¨le CLIP est disponible afin de tester celui-ci.
    """)

    st.sidebar.markdown("---")
    selected = st.sidebar.selectbox("Filtrer par catÃ©gorie", filter_options, index=0)

    st.title("ðŸ“Š Analyse exploratoire des donnÃ©es")
    st.markdown("Nous retrouvons ici les statistiques de base de notre jeu de donnÃ©es ainsi que quelques exemples de textes et d'images associÃ©es.")
    st.markdown("---")

    # Statistiques de base
    total = len(description)
    
    # Top row: TL = general stats, TR = histogram categories (or subcategories if filtered)
    top_left, top_right = st.columns([2, 4])

    with top_left:
        st.subheader("Statistiques gÃ©nÃ©rales")
        st.write(f"- Nombre d'images et descriptions rÃ©fÃ©rencÃ©es : **{total}**")

        # Liste des catÃ©gories
        categories = sorted(description["category"].unique())

        # Afficher chaque catÃ©gorie sur une nouvelle ligne pour une meilleure lisibilitÃ©
        categories_md = "\n".join(f"    * {c}" for c in categories)
        st.markdown("- Liste des catÃ©gories de produits :\n\n" + categories_md)

    # Ensure n_words exists
    if 'n_words' not in description.columns:
        description['n_words'] = description['product_description'].fillna('').astype(str).map(lambda s: len(s.split()))

    # Prepare filtered dataframe once
    if selected == "Toutes les catÃ©gories":
        df_filtered = description.copy()
    else:
        df_filtered = description[description['category'] == selected].copy()

    with top_right:
        if selected == "Toutes les catÃ©gories":
            cat_counts = description['category'].fillna('N/A').value_counts().reset_index()
            cat_counts.columns = ['category', 'count']
            cat_counts = cat_counts.sort_values('count', ascending=False)
            fig = px.bar(cat_counts, x='category', y='count',
                         labels={'category': 'CatÃ©gorie', 'count': 'Nombre de produits'},
                         title='Nombre de produits par catÃ©gorie')
            fig.update_xaxes(tickangle=-45)
            st.plotly_chart(fig, use_container_width=True)
        else:
            sub_counts = df_filtered['subcategory'].fillna('N/A').value_counts().reset_index()
            sub_counts.columns = ['subcategory', 'count']
            sub_counts = sub_counts.sort_values('count', ascending=False)
            fig = px.bar(sub_counts, x='subcategory', y='count',
                         labels={'subcategory': 'Sous-catÃ©gorie', 'count': 'Nombre de produits'},
                         title=f'Nombre de produits pour la catÃ©gorie : {selected}')
            fig.update_xaxes(tickangle=-45)
            st.plotly_chart(fig, use_container_width=True)

    st.markdown("---")
    
    # DeuxiÃ¨me partie sur les statistiques textuelles
    st.subheader("Descriptions des produits : analyses textuelles")

    # Bottom row: BL = boxplot n_words (3/5), BR = wordcloud (2/5)
    bot_left, bot_right = st.columns([3, 2])

    with bot_left:
        if selected == "Toutes les catÃ©gories":
            df_box = description.copy()
            df_box['category'] = df_box['category'].fillna('N/A').astype(str)
            box_fig = px.box(df_box, x='n_words', y='category', points='outliers',
                             labels={'category': 'CatÃ©gorie', 'n_words': 'Nombre de mots'},
                             title="Dispersion du nombre de mots par catÃ©gorie")
            box_fig.update_layout(margin=dict(l=20, r=10, t=50, b=120), height=450)
            box_fig.update_xaxes(tickangle=-45)
            st.plotly_chart(box_fig, use_container_width=True)
        else:
            df_box = df_filtered.copy()
            df_box['subcategory'] = df_box['subcategory'].fillna('N/A').astype(str)
            box_fig = px.box(df_box, x='n_words', y='subcategory', points='outliers',
                             labels={'subcategory': 'Sous-catÃ©gorie', 'n_words': 'Nombre de mots'},
                             title=f"Dispersion du nombre de mots â€” {selected}")
            box_fig.update_layout(margin=dict(l=20, r=10, t=50, b=120), height=450)
            box_fig.update_xaxes(tickangle=-45)
            st.plotly_chart(box_fig, use_container_width=True)

    with bot_right:
        text_corpus = ' '.join(df_filtered['product_description'].dropna().astype(str).tolist())
        if len(text_corpus.strip()) == 0:
            st.info('Pas de texte disponible pour gÃ©nÃ©rer un wordcloud.')
        else:
            try:
                wc = WordCloud(width=450, height=300, background_color='white', collocations=False).generate(text_corpus)
                img = wc.to_image()
                st.image(img, use_container_width=True)
            except Exception as e:
                # fallback: show top words as bar chart
                tokens = [w.lower() for w in text_corpus.split() if len(w) > 2]
                common = Counter(tokens).most_common(20)
                if len(common) == 0:
                    st.info('Aucun mot frÃ©quent Ã  afficher.')
                else:
                    df_wc = pd.DataFrame(common, columns=['word', 'count'])
                    fig_wc = px.bar(df_wc, x='word', y='count', title='Mots frÃ©quents (fallback)'),
                    st.plotly_chart(fig_wc, use_container_width=True)

    st.markdown("---")

    # Description des images
    st.subheader("Description des images : dimensions")

    # RÃ©cupÃ©rer les dimensions en utilisant la colonne `image` prÃ©sente dans `description`
    liste_largeur = []
    liste_hauteur = []
    images_col = description.get('image') if 'image' in description.columns else None
    if images_col is None:
        st.error("La colonne 'image' est absente de `produits_clip.csv`. Impossible de rÃ©cupÃ©rer les dimensions.")
        images_list = []
    else:
        images_list = images_col.fillna('').astype(str).tolist()

    for img_name in images_list:
        chemin_complet = os.path.join(IMG_DIR, img_name)
        try:
            w, h = imagesize.get(chemin_complet)
        except Exception:
            w, h = (np.nan, np.nan)
        liste_largeur.append(w)
        liste_hauteur.append(h)

    # Construire un dataframe alignÃ© avec `description` (inclut subcategory si prÃ©sent)
    dimensions_category = pd.DataFrame({
        'category': description['category'].fillna('N/A').astype(str).values,
        'subcategory': description['subcategory'].fillna('N/A').astype(str).values if 'subcategory' in description.columns else ['N/A'] * len(liste_largeur),
        'Largeur': liste_largeur,
        'Hauteur': liste_hauteur
    })

    # Convertir en numÃ©rique et nettoyer
    dimensions_category['Largeur'] = pd.to_numeric(dimensions_category['Largeur'], errors='coerce')
    dimensions_category['Hauteur'] = pd.to_numeric(dimensions_category['Hauteur'], errors='coerce')

    # Appliquer le filtre de la sidebar pour rendre les graphiques dynamiques
    if selected == "Toutes les catÃ©gories":
        dim_plot_df = dimensions_category.copy()
    else:
        dim_plot_df = dimensions_category[dimensions_category['category'] == selected].copy()

    # Deux colonnes identiques pour la dispersion largeur / hauteur
    img_left, img_right = st.columns(2)

    # Largeur
    df_w = dim_plot_df.dropna(subset=['Largeur'])
    with img_left:
        if df_w.empty:
            st.info('Aucune largeur disponible pour les images (vÃ©rifiez IMG_DIR et les noms de fichiers).')
            # Diagnostic: montrer les fichiers prÃ©sents dans IMG_DIR et les rÃ©sultats de imagesize.get
            try:
                files = sorted(os.listdir(IMG_DIR))
            except Exception:
                files = []
            sample_files = files[:50]
            diag_rows = []
            for fname in sample_files:
                path = os.path.join(IMG_DIR, fname)
                exists = os.path.exists(path)
                w = h = None
                try:
                    w, h = imagesize.get(path)
                except Exception:
                    w = h = None
                diag_rows.append({'file': fname, 'path': path, 'exists': exists, 'width': w, 'height': h})
            if len(diag_rows) > 0:
                st.markdown('**Diagnostic â€” fichiers dans IMG_DIR (extrait)**')
                st.dataframe(pd.DataFrame(diag_rows))
            else:
                st.write('Aucun fichier trouvÃ© dans IMG_DIR.')
            # Diagnostic: vÃ©rifier les chemins construits depuis labels (extrait)
            lab_rows = []
            for i in range(min(50, len(labels))):
                lab_name = str(labels[i])
                path = os.path.join(IMG_DIR, lab_name)
                exists = os.path.exists(path)
                w = h = None
                try:
                    w, h = imagesize.get(path)
                except Exception:
                    w = h = None
                lab_rows.append({'label_index': i, 'label': lab_name, 'path': path, 'exists': exists, 'width': w, 'height': h})
            st.markdown('**Diagnostic â€” chemins construits depuis `labels` (extrait)**')
            st.dataframe(pd.DataFrame(lab_rows))
        else:
            if selected == "Toutes les catÃ©gories":
                y_field = 'category'
                title = 'Dispersion des largeurs par catÃ©gorie'
            else:
                y_field = 'subcategory' if 'subcategory' in dim_plot_df.columns else 'category'
                title = f'Dispersion des largeurs â€” {selected}'
            label_map = {'category': 'CatÃ©gorie', 'subcategory': 'Sous-catÃ©gorie'}
            fig_w = px.box(df_w, x='Largeur', y=y_field, points='outliers',
                           labels={y_field: label_map.get(y_field, y_field), 'Largeur': 'Largeur (px)'},
                           title=title)
            fig_w.update_layout(margin=dict(l=20, r=10, t=50, b=120), height=450)
            fig_w.update_xaxes(tickangle=-45)
            st.plotly_chart(fig_w, use_container_width=True)

    # Hauteur
    df_h = dim_plot_df.dropna(subset=['Hauteur'])
    with img_right:
        if df_h.empty:
            st.info('Aucune hauteur disponible pour les images (vÃ©rifiez IMG_DIR et les noms de fichiers).')
        else:
            if selected == "Toutes les catÃ©gories":
                y_field = 'category'
                title = 'Dispersion des hauteurs par catÃ©gorie'
            else:
                y_field = 'subcategory' if 'subcategory' in dim_plot_df.columns else 'category'
                title = f'Dispersion des hauteurs â€” {selected}'
            label_map = {'category': 'CatÃ©gorie', 'subcategory': 'Sous-catÃ©gorie'}
            fig_h = px.box(df_h, x='Hauteur', y=y_field, points='outliers',
                           labels={y_field: label_map.get(y_field, y_field), 'Hauteur': 'Hauteur (px)'},
                           title=title)
            fig_h.update_layout(margin=dict(l=20, r=10, t=50, b=120), height=450)
            fig_h.update_xaxes(tickangle=-45)
            st.plotly_chart(fig_h, use_container_width=True)

    st.markdown("---")
    
    # Exemples d'images et de textes (filtrÃ©s par la sidebar)
    st.subheader("Exemples d'images et de descriptions")
    df_examples = df_filtered if 'df_filtered' in locals() else description.copy()
    # limiter le nombre d'exemples affichÃ©s
    n_examples = min(4, len(df_examples))
    if n_examples == 0:
        st.info('Aucun item Ã  afficher pour le filtre sÃ©lectionnÃ©.')
    else:
        cols = st.columns(4)
        for idx in range(n_examples):
            row = df_examples.iloc[idx]
            img_name = row.get('image', '')
            img_path = os.path.join(IMG_DIR, img_name) if img_name else None
            img_cv = cv2_read_rgb(img_path) if img_path else None
            with cols[idx % 4]:
                if img_cv is not None:
                    st.image(img_cv, caption=str(img_name), width=180)
                else:
                    st.write(f'Image introuvable: {img_name}')
                desc = row.get('product_description', '')
                if isinstance(desc, str) and len(desc) > 0:
                    snippet = desc.replace('\n', ' ')[:250]
                    st.caption(snippet + ('...' if len(desc) > 250 else ''))

    st.markdown("---")

# ---------------------------
# Page 2 : PrÃ©diction CLIP
# ---------------------------
# -----------------------------------
# CLIP (API Hugging Face)
# -----------------------------------
import requests

# URL de l'API d'infÃ©rence Hugging Face pour CLIP
API_URL = "https://router.huggingface.co/models/laion/CLIP-ViT-B-32-laion2B-s34B-b79K"

def query_clip_api(image_bytes):
    """
    Envoie l'image Ã  l'API Hugging Face pour obtenir l'embedding.
    """
    # RÃ©cupÃ©rer le token depuis les secrets Streamlit
    if "HF_API_TOKEN" in st.secrets:
        headers = {"Authorization": f"Bearer {st.secrets['HF_API_TOKEN']}"}
    else:
        st.error("âš ï¸ Le token API Hugging Face est manquant. Ajoutez `HF_API_TOKEN` dans `.streamlit/secrets.toml` ou les secrets du Cloud.")
        return None

    try:
        response = requests.post(API_URL, headers=headers, data=image_bytes)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"Erreur lors de l'appel API : {e}")
        return None

# -----------------------------------
# CLASSIFIEUR RF (cachÃ© correctement)
# -----------------------------------
@st.cache_resource
def load_classifier(embeddings, labels_or_categories):
    le = LabelEncoder()
    y_encoded = le.fit_transform(labels_or_categories)
    clf = RandomForestClassifier(n_estimators=200, random_state=42)
    clf.fit(embeddings, y_encoded)
    return clf, le

with tab_search:

    st.title("ðŸ”Ž Recherche et PrÃ©diction dâ€™Images avec CLIP")
    st.markdown("Testez le modÃ¨le CLIP en choisissant une image du dataset.")

    try:
        current_category = selected
    except NameError:
        current_category = "Toutes les catÃ©gories"

    dataset_df = description if current_category == "Toutes les catÃ©gories" else description[description["category"] == current_category]
    dataset_images = dataset_df.get('image', pd.Series([])).fillna('').astype(str).tolist()

    selected_dataset_image = st.selectbox("Choisir une image du dataset", [""] + dataset_images)

    if selected_dataset_image:

        sel_path = os.path.join(IMG_DIR, selected_dataset_image)
        sel_img = cv2_read_rgb(sel_path)

        # Index dans le CSV
        matches = description.index[description['image'].fillna('').astype(str) == selected_dataset_image].tolist()
        idx = matches[0] if matches else None

        if sel_img is not None:
            st.image(sel_img, caption=selected_dataset_image, width=300)
            # Afficher la vraie catÃ©gorie / sous-catÃ©gorie associÃ©e si disponible
            if idx is not None:
                true_cat = description.at[idx, 'category'] if 'category' in description.columns else None
                info_text = ""
                if true_cat is not None:
                    info_text += f"Vraie catÃ©gorie : {true_cat}"
                if info_text:
                    st.info(info_text)

            # Chargement classifieur (rapide)
            clf, le = load_classifier(embeddings, labels)

            if st.button("PrÃ©dire la catÃ©gorie"):
                # Lire l'image en binaire pour l'API
                with open(sel_path, "rb") as f:
                    image_bytes = f.read()
                
                with st.spinner("Interrogation de l'API Hugging Face..."):
                    api_response = query_clip_api(image_bytes)
                
                if api_response is not None:
                    # L'API feature-extraction renvoie gÃ©nÃ©ralement une liste (l'embedding)
                    if isinstance(api_response, list) and len(api_response) > 0:
                        emb_vec = np.array(api_response)
                        
                        # Si c'est une liste de listes (batch), on prend le premier
                        if emb_vec.ndim > 1:
                            emb_vec = emb_vec[0]
                            
                        emb_vec = emb_vec.reshape(1, -1)
                        
                        # Normalisation (important pour CLIP)
                        emb_vec = emb_vec / np.linalg.norm(emb_vec, axis=1, keepdims=True)

                        # PrÃ©diction RF
                        try:
                            pred_enc = clf.predict(emb_vec)[0]
                            proba = clf.predict_proba(emb_vec).max()
                            pred_label = le.inverse_transform([pred_enc])[0]
                            st.success(f"ðŸŽ¯ PrÃ©diction : {pred_label} â€” Confiance : {proba:.2%}")
                        except Exception as e:
                            st.error(f"Erreur lors de la classification : {e}")
                            st.write("Shape embedding reÃ§u:", emb_vec.shape)
                    else:
                        st.error(f"RÃ©ponse API inattendue : {api_response}")

        else:
            st.warning("Image introuvable dans IMG_DIR.")
